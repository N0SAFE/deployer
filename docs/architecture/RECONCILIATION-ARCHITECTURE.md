# Reconciliation Architecture - Production-Grade Deployment System

> **Goal**: Build a deployment system that handles crashes, server restarts, load balancing across multiple servers, and maintains consistency between desired state (database) and actual state (running containers).

## Table of Contents
1. [Architecture Overview](#architecture-overview)
2. [Reconciliation Patterns](#reconciliation-patterns)
3. [Multi-Server Coordination](#multi-server-coordination)
4. [Crash Recovery](#crash-recovery)
5. [Implementation Roadmap](#implementation-roadmap)

---

## Architecture Overview

### Desired State vs Actual State

**Desired State** (Source of Truth):
- **Database**: Projects, deployments, services configuration
- **What SHOULD be running**: Active projects with their latest successful deployments

**Actual State** (Current Reality):
- **Docker Containers**: Running, stopped, or crashed containers
- **Traefik Routes**: Active routing configurations
- **Volume Data**: Deployed files and symlinks

**Reconciliation Goal**: Continuously align actual state with desired state.

### Core Principles

1. **Database is the Single Source of Truth**
   - All deployment state lives in PostgreSQL
   - Containers are ephemeral and can be recreated
   - Labels on containers reference database records

2. **Idempotent Operations**
   - Reconciliation can run multiple times safely
   - No side effects from repeated reconciliation
   - Eventual consistency guaranteed

3. **Crash Resilience**
   - System recovers from crashes automatically
   - In-progress deployments can resume or rollback
   - No manual intervention required

4. **Multi-Server Safe**
   - Multiple API servers can share the load
   - Only one server reconciles at a time (leader election)
   - Shared database coordinates state

---

## Reconciliation Patterns

### Pattern 1: Kubernetes-Style Desired State Reconciliation

**How Kubernetes Does It:**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 3  # Desired state
  selector:
    matchLabels:
      app: nginx
```

**Controller Loop:**
```
while true:
  desired = get_from_database()
  actual = get_from_docker()
  
  if actual != desired:
    reconcile(desired, actual)
  
  sleep(interval)
```

**Our Implementation:**
```typescript
// Database stores desired state
interface DesiredState {
  projectId: string;
  serviceType: 'static-file' | 'docker' | 'git-repo';
  currentDeploymentId: string;
  status: 'active' | 'inactive';
  config: {
    domain: string;
    replicas: number; // Future: for load balancing
  };
}

// Reconciliation loop
async reconcile() {
  const desiredProjects = await db.select().from(projects).where(eq(projects.status, 'active'));
  const actualContainers = await docker.listContainers({ all: true });
  
  for (const project of desiredProjects) {
    const container = findContainerForProject(actualContainers, project.id);
    
    if (!container) {
      // Container missing â†’ create it
      await createProjectContainer(project);
    } else if (container.State !== 'running') {
      // Container stopped â†’ restart it
      await docker.getContainer(container.Id).start();
    } else if (!hasCorrectDeployment(container, project)) {
      // Container running wrong deployment â†’ update it
      await updateDeployment(project);
    }
  }
  
  // Clean up containers for deleted projects
  for (const container of actualContainers) {
    const projectId = container.Labels['deployer.project_server'];
    if (projectId && !desiredProjects.find(p => p.id === projectId)) {
      await removeContainer(container.Id);
    }
  }
}
```

### Pattern 2: Docker Swarm-Style Service Management

**How Docker Swarm Does It:**
- Services define desired replicas
- Swarm maintains exact replica count
- Tasks (containers) automatically replaced on failure
- Raft consensus ensures consistency

**Our Implementation:**
```typescript
interface ServiceDefinition {
  projectId: string;
  replicas: number; // For future horizontal scaling
  updateStrategy: 'rolling' | 'recreate';
  healthCheck: {
    enabled: boolean;
    endpoint: string;
    interval: number;
  };
}

async reconcileService(service: ServiceDefinition) {
  const containers = await getContainersForService(service.projectId);
  
  // Ensure correct number of replicas
  if (containers.length < service.replicas) {
    const missing = service.replicas - containers.length;
    for (let i = 0; i < missing; i++) {
      await createReplica(service);
    }
  } else if (containers.length > service.replicas) {
    const excess = containers.length - service.replicas;
    await removeOldestReplicas(containers, excess);
  }
  
  // Ensure all replicas are healthy
  for (const container of containers) {
    if (service.healthCheck.enabled) {
      const healthy = await checkHealth(container, service.healthCheck);
      if (!healthy) {
        await replaceUnhealthyContainer(container, service);
      }
    }
  }
}
```

### Pattern 3: Vercel-Style Atomic Deployments

**How Vercel Does It:**
- Each deployment gets a unique immutable ID
- Files deployed to new directory
- Atomic symlink switch activates deployment
- Previous deployments kept for instant rollback

**Our Current Implementation** (already doing this!):
```bash
# Volume structure
/srv/static/
  â”œâ”€â”€ {service-name}/
  â”‚   â”œâ”€â”€ deployment-{id-1}/     # Immutable deployment
  â”‚   â”œâ”€â”€ deployment-{id-2}/     # Immutable deployment
  â”‚   â”œâ”€â”€ deployment-{id-3}/     # Immutable deployment
  â”‚   â””â”€â”€ current â†’ deployment-{id-3}  # Atomic switch

/var/www/html/
  â””â”€â”€ * â†’ /srv/static/{service-name}/current/*  # Symlinks to current
```

**Reconciliation for Atomic Deployments:**
```typescript
async reconcileDeployment(project: Project) {
  const latestDeployment = await getLatestSuccessfulDeployment(project.id);
  const currentSymlink = await readSymlink(`/srv/static/${project.name}/current`);
  
  if (currentSymlink !== `deployment-${latestDeployment.id}`) {
    // Symlink points to wrong deployment â†’ fix it
    await atomicSymlinkSwitch(
      `/srv/static/${project.name}/current`,
      `deployment-${latestDeployment.id}`
    );
    
    // Update webroot symlinks
    await updateWebrootSymlinks(project, latestDeployment);
  }
  
  // Verify deployment files exist
  const filesExist = await verifyDeploymentFiles(latestDeployment);
  if (!filesExist) {
    // Files missing â†’ redeploy
    await redeployFromSource(latestDeployment);
  }
}
```

### Pattern 4: PM2-Style State Resurrection

**How PM2 Does It:**
```bash
pm2 save          # Save current process list
# After server restart
pm2 resurrect     # Restore saved processes
```

**Our Implementation:**
```typescript
interface DeploymentSnapshot {
  timestamp: Date;
  projects: Array<{
    id: string;
    containerId: string;
    deploymentId: string;
    status: 'running' | 'stopped';
    config: Record<string, any>;
  }>;
}

// On startup
async onModuleInit() {
  this.logger.log('Resurrecting deployment state...');
  
  // 1. Get desired state from database
  const activeProjects = await this.getActiveProjects();
  
  // 2. Get actual state from Docker
  const runningContainers = await this.getRunningContainers();
  
  // 3. Reconcile
  for (const project of activeProjects) {
    const container = runningContainers.find(c => 
      c.Labels['deployer.project_server'] === project.id
    );
    
    if (!container) {
      this.logger.warn(`Project ${project.name} should be running but container not found`);
      await this.resurrectProject(project);
    } else if (container.State !== 'running') {
      this.logger.warn(`Project ${project.name} container exists but stopped`);
      await this.startContainer(container.Id);
    } else {
      this.logger.log(`Project ${project.name} is healthy`);
    }
  }
  
  // 4. Clean up zombies
  await this.cleanupZombieContainers();
}

async resurrectProject(project: Project) {
  const latestDeployment = await this.getLatestDeployment(project.id);
  
  if (!latestDeployment) {
    this.logger.error(`No deployment found for project ${project.name}`);
    return;
  }
  
  // Recreate container from database state
  await this.createProjectContainer(project, latestDeployment);
  
  // Verify deployment files exist
  await this.verifyDeploymentFiles(latestDeployment);
  
  // Update Traefik routing
  await this.updateTraefikRoutes(project);
}
```

---

## Multi-Server Coordination

### Challenge: Multiple API Servers

When running multiple API servers for high availability:
- Each server has its own reconciliation cron
- Without coordination, they'll fight each other
- Need **leader election** to ensure only one reconciles

### Solution 1: Database-Based Leader Election

**Using PostgreSQL Advisory Locks:**
```typescript
@Injectable()
export class LeaderElectionService {
  private isLeader = false;
  private readonly LOCK_KEY = 1234567890; // Arbitrary unique number
  
  async tryAcquireLeadership(): Promise<boolean> {
    try {
      // Try to acquire advisory lock (non-blocking)
      const result = await this.db.execute(
        `SELECT pg_try_advisory_lock(${this.LOCK_KEY}) as acquired`
      );
      
      this.isLeader = result.rows[0].acquired;
      return this.isLeader;
    } catch (error) {
      this.logger.error('Failed to acquire leadership:', error);
      return false;
    }
  }
  
  async releaseLeadership(): Promise<void> {
    if (this.isLeader) {
      await this.db.execute(
        `SELECT pg_advisory_unlock(${this.LOCK_KEY})`
      );
      this.isLeader = false;
    }
  }
  
  async isCurrentLeader(): Promise<boolean> {
    return this.isLeader;
  }
}

// Modified reconciliation
@Cron(CronExpression.EVERY_MINUTE)
async autoCleanup() {
  const acquired = await this.leaderElection.tryAcquireLeadership();
  
  if (!acquired) {
    this.logger.debug('Not leader, skipping reconciliation');
    return;
  }
  
  try {
    await this.reconcileAllContainers();
    await this.cleanupZombieContainers();
  } finally {
    await this.leaderElection.releaseLeadership();
  }
}
```

**Pros:**
- No external dependencies
- Automatic failover (lock released on disconnect)
- Simple implementation

**Cons:**
- Requires PostgreSQL 9.1+
- Lock held during entire reconciliation

### Solution 2: Redis-Based Leader Election with Heartbeat

**Using Redis with TTL:**
```typescript
@Injectable()
export class RedisLeaderElectionService {
  private readonly LEADER_KEY = 'deployer:leader';
  private readonly HEARTBEAT_INTERVAL = 5000; // 5 seconds
  private readonly LEADER_TTL = 10; // 10 seconds
  private leaderId: string;
  private heartbeatInterval: NodeJS.Timeout | null = null;
  
  constructor(private readonly redis: Redis) {
    this.leaderId = `${os.hostname()}-${process.pid}`;
  }
  
  async tryBecomeLeader(): Promise<boolean> {
    // Try to set leader key with NX (only if not exists)
    const result = await this.redis.set(
      this.LEADER_KEY,
      this.leaderId,
      'EX', this.LEADER_TTL,
      'NX'
    );
    
    if (result === 'OK') {
      this.startHeartbeat();
      return true;
    }
    
    return false;
  }
  
  private startHeartbeat() {
    this.heartbeatInterval = setInterval(async () => {
      // Extend TTL if we're still leader
      const currentLeader = await this.redis.get(this.LEADER_KEY);
      if (currentLeader === this.leaderId) {
        await this.redis.expire(this.LEADER_KEY, this.LEADER_TTL);
      } else {
        this.stopHeartbeat();
      }
    }, this.HEARTBEAT_INTERVAL);
  }
  
  private stopHeartbeat() {
    if (this.heartbeatInterval) {
      clearInterval(this.heartbeatInterval);
      this.heartbeatInterval = null;
    }
  }
  
  async isLeader(): Promise<boolean> {
    const currentLeader = await this.redis.get(this.LEADER_KEY);
    return currentLeader === this.leaderId;
  }
  
  async stepDown() {
    const currentLeader = await this.redis.get(this.LEADER_KEY);
    if (currentLeader === this.leaderId) {
      await this.redis.del(this.LEADER_KEY);
    }
    this.stopHeartbeat();
  }
}
```

**Pros:**
- Automatic failover (TTL expires if leader crashes)
- Heartbeat ensures liveness
- Fast leader detection

**Cons:**
- Requires Redis
- More complex implementation

### Solution 3: Event-Driven Coordination

**Using Database Change Notifications:**
```typescript
// Server A makes a change
await db.update(deployments)
  .set({ status: 'active' })
  .where(eq(deployments.id, deploymentId));

await redis.publish('deployer:deployment:updated', JSON.stringify({
  projectId,
  deploymentId,
  action: 'activated'
}));

// Server B subscribes
redis.subscribe('deployer:deployment:updated');
redis.on('message', async (channel, message) => {
  const event = JSON.parse(message);
  await this.handleDeploymentUpdate(event);
});
```

**Pros:**
- Real-time updates across servers
- No polling needed
- Efficient use of resources

**Cons:**
- Requires Redis pub/sub
- More complex architecture

### Recommended Approach: Hybrid

Use **PostgreSQL advisory locks** for simple deployments, with option to add Redis for high-scale:

```typescript
@Injectable()
export class CoordinationService {
  constructor(
    @Inject('COORDINATION_STRATEGY') 
    private readonly strategy: 'postgres' | 'redis'
  ) {}
  
  async executeAsLeader<T>(
    operation: () => Promise<T>
  ): Promise<T | null> {
    const service = this.strategy === 'redis' 
      ? this.redisLeader 
      : this.postgresLeader;
    
    const acquired = await service.tryAcquireLeadership();
    if (!acquired) {
      return null;
    }
    
    try {
      return await operation();
    } finally {
      await service.releaseLeadership();
    }
  }
}

// Usage
@Cron(CronExpression.EVERY_MINUTE)
async autoCleanup() {
  await this.coordination.executeAsLeader(async () => {
    await this.reconcileAllContainers();
    await this.cleanupZombieContainers();
  });
}
```

---

## Crash Recovery

### Scenario 1: API Server Crashes During Deployment

**Problem:**
1. Deployment starts: files copying to volume
2. API crashes
3. Container left in intermediate state
4. Symlinks not updated
5. Database shows "building" status forever

**Solution: Resumable Deployments**

```typescript
enum DeploymentPhase {
  QUEUED = 'queued',
  PULLING_SOURCE = 'pulling_source',
  BUILDING = 'building',
  COPYING_FILES = 'copying_files',
  CREATING_SYMLINKS = 'creating_symlinks',
  UPDATING_ROUTES = 'updating_routes',
  HEALTH_CHECK = 'health_check',
  ACTIVE = 'active',
  FAILED = 'failed',
}

interface DeploymentCheckpoint {
  deploymentId: string;
  phase: DeploymentPhase;
  progress: number; // 0-100
  metadata: {
    sourceCommit?: string;
    filesCopied?: number;
    totalFiles?: number;
    containerId?: string;
  };
  lastUpdated: Date;
}

// On startup, resume incomplete deployments
async resumeIncompleteDeployments() {
  const incomplete = await db.select()
    .from(deployments)
    .where(
      and(
        inArray(deployments.status, ['queued', 'building']),
        lt(deployments.updatedAt, new Date(Date.now() - 5 * 60 * 1000)) // Stuck for 5+ minutes
      )
    );
  
  for (const deployment of incomplete) {
    this.logger.warn(`Found incomplete deployment ${deployment.id} in phase ${deployment.phase}`);
    
    // Check if we can resume or need to retry
    const canResume = await this.canResumeDeployment(deployment);
    
    if (canResume) {
      this.logger.log(`Resuming deployment ${deployment.id} from phase ${deployment.phase}`);
      await this.resumeDeploymentFromPhase(deployment);
    } else {
      this.logger.warn(`Cannot resume deployment ${deployment.id}, marking as failed`);
      await this.markDeploymentFailed(deployment.id, 'Cannot resume after crash');
    }
  }
}

async resumeDeploymentFromPhase(deployment: Deployment) {
  switch (deployment.phase) {
    case DeploymentPhase.COPYING_FILES:
      // Files might be partially copied
      // Verify what's there and continue
      const fileCount = await this.countDeploymentFiles(deployment.id);
      if (fileCount > 0) {
        // Some files copied, continue from symlink creation
        await this.createSymlinks(deployment);
      } else {
        // No files, restart copy
        await this.copyFiles(deployment);
      }
      break;
      
    case DeploymentPhase.CREATING_SYMLINKS:
      // Safe to retry symlink creation (idempotent)
      await this.createSymlinks(deployment);
      break;
      
    case DeploymentPhase.UPDATING_ROUTES:
      // Safe to retry route updates (idempotent)
      await this.updateTraefikRoutes(deployment);
      break;
      
    default:
      // For other phases, safer to restart
      await this.restartDeployment(deployment);
  }
}
```

### Scenario 2: Container Crashes or Stops

**Problem:**
- Container exits unexpectedly
- Project goes offline
- No automatic recovery

**Solution: Restart Policy + Health Monitoring**

```typescript
// Add restart policy to container creation
const container = await docker.createContainer({
  name: `project-http-${projectId}`,
  Image: 'custom-lighttpd:latest',
  HostConfig: {
    RestartPolicy: {
      Name: 'unless-stopped',
      MaximumRetryCount: 3
    },
    Binds: [`${volumeName}:/srv/static`]
  },
  Healthcheck: {
    Test: ['CMD', 'wget', '--quiet', '--tries=1', '--spider', 'http://localhost:80/'],
    Interval: 30000000000, // 30 seconds in nanoseconds
    Timeout: 10000000000,  // 10 seconds
    Retries: 3
  }
});

// Health monitoring service
@Injectable()
export class HealthMonitorService {
  @Cron(CronExpression.EVERY_30_SECONDS)
  async checkContainerHealth() {
    const containers = await this.getProjectContainers();
    
    for (const container of containers) {
      const inspect = await docker.getContainer(container.Id).inspect();
      
      if (inspect.State.Health?.Status === 'unhealthy') {
        this.logger.error(`Container ${container.Id} is unhealthy, restarting...`);
        await this.restartContainer(container.Id);
      }
      
      if (inspect.State.Status === 'exited' || inspect.State.Status === 'dead') {
        this.logger.error(`Container ${container.Id} has stopped, restarting...`);
        await this.startContainer(container.Id);
      }
    }
  }
}
```

### Scenario 3: Data Corruption (Symlinks Broken)

**Problem:**
- Symlinks deleted or corrupted
- Files exist but not accessible
- Manual intervention needed

**Solution: Self-Healing Reconciliation**

```typescript
async reconcileSymlinks(project: Project) {
  const latestDeployment = await this.getLatestSuccessfulDeployment(project.id);
  if (!latestDeployment) return;
  
  const volumePath = `/srv/static/${project.name}`;
  
  try {
    // Check if current symlink exists and is valid
    const currentSymlink = await this.readSymlink(`${volumePath}/current`);
    const expectedTarget = `deployment-${latestDeployment.id}`;
    
    if (currentSymlink !== expectedTarget) {
      this.logger.warn(`Symlink mismatch for ${project.name}: ${currentSymlink} !== ${expectedTarget}`);
      await this.createSymlink(`${volumePath}/current`, expectedTarget);
    }
    
    // Check webroot symlinks
    const deploymentFiles = await this.listDeploymentFiles(latestDeployment.id);
    
    for (const file of deploymentFiles) {
      const webrootPath = `/var/www/html/${file}`;
      const targetPath = `${volumePath}/current/${file}`;
      
      const symlinkTarget = await this.readSymlink(webrootPath);
      if (symlinkTarget !== targetPath) {
        this.logger.warn(`Webroot symlink broken for ${file}`);
        await this.createSymlink(webrootPath, targetPath);
      }
    }
  } catch (error) {
    this.logger.error(`Failed to reconcile symlinks for ${project.name}:`, error);
    // Trigger full redeployment as last resort
    await this.triggerRedeployment(project, latestDeployment);
  }
}
```

### Scenario 4: Split-Brain (Multiple Servers Disagree)

**Problem:**
- Server A thinks deployment X is active
- Server B thinks deployment Y is active
- Containers out of sync with database

**Solution: Database as Single Source of Truth**

```typescript
async resolveConflicts(project: Project) {
  // Always trust the database
  const dbDeployment = await db.select()
    .from(deployments)
    .where(
      and(
        eq(deployments.projectId, project.id),
        eq(deployments.status, 'active')
      )
    )
    .orderBy(desc(deployments.createdAt))
    .limit(1);
  
  if (!dbDeployment.length) {
    this.logger.error(`No active deployment in database for ${project.name}`);
    return;
  }
  
  const desiredDeployment = dbDeployment[0];
  
  // Get all containers for this project across all servers
  const containers = await docker.listContainers({
    all: true,
    filters: {
      label: [`deployer.project_server=${project.id}`]
    }
  });
  
  for (const container of containers) {
    const containerDeploymentId = container.Labels['deployer.deployment_id'];
    
    if (containerDeploymentId !== desiredDeployment.id) {
      this.logger.warn(
        `Container ${container.Id} has wrong deployment: ` +
        `${containerDeploymentId} !== ${desiredDeployment.id}`
      );
      
      // Recreate container with correct deployment
      await this.recreateContainerWithDeployment(container, desiredDeployment);
    }
  }
}
```

---

## Implementation Roadmap

### Phase 1: Enhanced Reconciliation (Current)
**Status**: âœ… Mostly Complete

- [x] Zombie container cleanup
- [x] Restart stopped containers
- [x] Verify Traefik labels
- [x] Run on startup
- [x] Run hourly via cron
- [ ] Add deployment phase tracking
- [ ] Add health checks to containers

### Phase 2: Crash Recovery
**Status**: ðŸ”„ In Progress

- [ ] Resume incomplete deployments on startup
- [ ] Add deployment checkpoints (phase tracking)
- [ ] Symlink self-healing
- [ ] Container restart policies
- [ ] Health monitoring service
- [ ] Automatic rollback on health check failure

### Phase 3: Multi-Server Coordination
**Status**: ðŸ“‹ Planned

- [ ] PostgreSQL advisory lock leader election
- [ ] Leader-only reconciliation
- [ ] Heartbeat mechanism
- [ ] Graceful failover
- [ ] Optional Redis coordination (for scale)

### Phase 4: Advanced Features
**Status**: ðŸ“‹ Future

- [ ] Horizontal scaling (multiple replicas per project)
- [ ] Blue-green deployments
- [ ] Canary deployments
- [ ] Automatic rollback based on error rate
- [ ] Distributed tracing for deployments
- [ ] Deployment analytics and monitoring

### Implementation Priority

**High Priority (Production Critical):**
1. Deployment phase tracking â† Prevents stuck deployments
2. Resume incomplete deployments â† Handles crashes
3. Container health checks â† Ensures uptime
4. Symlink reconciliation â† Prevents broken sites

**Medium Priority (Reliability):**
5. Leader election â† Enables multi-server
6. Health monitoring service â† Proactive recovery
7. Restart policies â† Automatic recovery

**Low Priority (Nice to Have):**
8. Redis coordination â† Only for high scale
9. Blue-green deployments â† Advanced feature
10. Deployment analytics â† Observability

---

## Testing Strategy

### Unit Tests
```typescript
describe('ReconciliationService', () => {
  it('should restart stopped containers for active projects', async () => {
    // Mock database with active project
    // Mock Docker with stopped container
    // Expect container to be started
  });
  
  it('should remove containers for deleted projects', async () => {
    // Mock database without project
    // Mock Docker with orphaned container
    // Expect container to be removed
  });
  
  it('should fix broken symlinks', async () => {
    // Mock filesystem with wrong symlinks
    // Expect symlinks to be corrected
  });
});
```

### Integration Tests
```typescript
describe('Crash Recovery', () => {
  it('should resume deployment after crash during file copy', async () => {
    // Start deployment
    // Simulate crash by killing process
    // Restart service
    // Verify deployment completes
  });
  
  it('should clean up partial deployments', async () => {
    // Create partial deployment
    // Run reconciliation
    // Verify cleanup or completion
  });
});
```

### Load Tests
```typescript
describe('Multi-Server Coordination', () => {
  it('should handle multiple servers without conflicts', async () => {
    // Start 3 API servers
    // Deploy project from server 1
    // Verify all servers see same state
    // Stop server 1
    // Verify server 2 or 3 takes over
  });
});
```

---

## Monitoring and Observability

### Metrics to Track
```typescript
interface ReconciliationMetrics {
  // Reconciliation health
  lastReconciliationTime: Date;
  reconciliationDuration: number;
  reconciliationErrors: number;
  
  // State metrics
  activeProjects: number;
  runningContainers: number;
  stoppedContainers: number;
  zombieContainers: number;
  
  // Deployment metrics
  deploymentsInProgress: number;
  deploymentsStuck: number;
  averageDeploymentTime: number;
  
  // Health metrics
  unhealthyContainers: number;
  brokenSymlinks: number;
  missingDeployments: number;
}
```

### Alerts
1. **Critical**: Reconciliation failing for >15 minutes
2. **Critical**: >3 deployments stuck in building phase
3. **Warning**: >5 zombie containers detected
4. **Warning**: Container restarted >3 times in 10 minutes
5. **Info**: Leader election failover occurred

---

## Conclusion

This reconciliation architecture provides:

âœ… **Crash Resilience** - System recovers from any failure automatically
âœ… **Multi-Server Safe** - Multiple API servers coordinate properly  
âœ… **Self-Healing** - Detects and fixes inconsistencies automatically
âœ… **Production Ready** - Handles edge cases and failure modes
âœ… **Scalable** - Can grow from 1 to N servers seamlessly

The implementation follows proven patterns from Kubernetes, Docker Swarm, and Vercel, adapted for our specific deployment architecture.
